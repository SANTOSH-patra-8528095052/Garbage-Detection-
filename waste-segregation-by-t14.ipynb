{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4235079,"sourceType":"datasetVersion","datasetId":2495983},{"sourceId":11119045,"sourceType":"datasetVersion","datasetId":6933434}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet50\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T20:02:39.998657Z","iopub.execute_input":"2025-03-21T20:02:39.999035Z","iopub.status.idle":"2025-03-21T20:02:57.784911Z","shell.execute_reply.started":"2025-03-21T20:02:39.998998Z","shell.execute_reply":"2025-03-21T20:02:57.783909Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def fix_and_clean_images(directory):\n    num_fixed = 0\n    num_removed = 0\n\n    for root, _, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n            try:\n                with Image.open(file_path) as img:\n                    img = img.convert(\"RGB\")  # Ensure it's RGB\n                    img = img.resize((256, 256))  # Resize to standard size\n                    img.save(file_path, \"JPEG\")  # Save as JPG\n                    num_fixed += 1\n            except (OSError, UnidentifiedImageError):\n                print(f\"❌ Removing corrupted image: {file_path}\")\n                os.remove(file_path)\n                num_removed += 1\n\n    print(f\"✅ Fixed {num_fixed} images and removed {num_removed} corrupted images from {directory}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport os\n\ndef resize_images(input_folder, output_folder, size=(224, 224)):\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n    for filename in os.listdir(input_folder):\n        img_path = os.path.join(input_folder, filename)\n        img = tf.io.read_file(img_path)\n        img = tf.image.decode_image(img)\n        img = tf.image.resize(img, size)\n        img = tf.cast(img, tf.uint8)\n        tf.io.write_file(os.path.join(output_folder, filename), tf.io.encode_jpeg(img))\n    print(\"Resizing complete!\")\n\nresize_images('Tanmay --->  path_to_input_folder', 'Tanmay --->  path_to_output_folder', (224, 224))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_path = \"/kaggle/input/waste-segregation-image-dataset/Dataset\"\ntrain_dir = os.path.join(dataset_path, \"train\")\ntest_dir = os.path.join(dataset_path, \"val\")\nfix_and_clean_images(train_dir)\nfix_and_clean_images(test_dir)\nprint(\"Classes:\", os.listdir(train_dir))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T16:34:09.046103Z","iopub.execute_input":"2025-03-21T16:34:09.046480Z","iopub.status.idle":"2025-03-21T16:34:09.067234Z","shell.execute_reply.started":"2025-03-21T16:34:09.046445Z","shell.execute_reply":"2025-03-21T16:34:09.065903Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nIMG_SIZE = (224, 224)  \nBATCH_SIZE = 32  \n\n# Data Augmentation & Normalization\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,  \n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2 \n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode=\"categorical\",\n    subset=\"training\"\n)\n\nval_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode=\"categorical\",\n    subset=\"validation\"\n)\n\n# Check class-to-index mapping\nprint(\"Class Indices:\", train_generator.class_indices)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T16:34:15.577643Z","iopub.execute_input":"2025-03-21T16:34:15.578001Z","iopub.status.idle":"2025-03-21T16:34:35.165599Z","shell.execute_reply.started":"2025-03-21T16:34:15.577974Z","shell.execute_reply":"2025-03-21T16:34:35.164709Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimages, labels = next(train_generator)\nfig, axes = plt.subplots(3, 3, figsize=(8, 8))\naxes = axes.flatten()\nfor img, ax in zip(images[:9], axes):\n    ax.imshow(img)\n    ax.axis(\"off\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T16:34:59.250389Z","iopub.execute_input":"2025-03-21T16:34:59.250767Z","iopub.status.idle":"2025-03-21T16:35:00.726974Z","shell.execute_reply.started":"2025-03-21T16:34:59.250736Z","shell.execute_reply":"2025-03-21T16:35:00.725419Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam \nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, MaxPooling2D\nbase_model = ResNet50(weights=\"/kaggle/input/resnet50-weights/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\", \n                      include_top=False, input_shape=(224, 224, 3))\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\nx = base_model.output\nx = MaxPooling2D(pool_size=(2, 2))(x)  \nx = GlobalAveragePooling2D()(x) \nx = Dense(512, activation=\"relu\")(x)\nx = Dropout(0.3)(x)  \nx = MaxPooling2D(pool_size=(2, 2))(x) \nx = Dense(256, activation=\"relu\")(x)\nx = Dropout(0.3)(x)  \noutput_layer = Dense(len(train_generator.class_indices), activation=\"softmax\")(x)  # Output layer\n\nmodel = Model(inputs=base_model.input, outputs=output_layer)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T16:48:53.279451Z","iopub.execute_input":"2025-03-21T16:48:53.279950Z","iopub.status.idle":"2025-03-21T16:48:56.778397Z","shell.execute_reply.started":"2025-03-21T16:48:53.279908Z","shell.execute_reply":"2025-03-21T16:48:56.777130Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for learning_rate in [0.01]:\n    model.compile(optimizer=Adam(learning_rate=learning_rate), \n                  loss=\"categorical_crossentropy\", \n                  metrics=[\"accuracy\"])\n    EPOCHS = 10  \n\n    history = model.fit(\n        train_generator,\n        validation_data=val_generator,\n        epochs=EPOCHS,\n        verbose=1,\n        use_multiprocessing=False  \n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T16:48:59.329230Z","iopub.execute_input":"2025-03-21T16:48:59.329622Z","iopub.status.idle":"2025-03-21T17:08:41.610059Z","shell.execute_reply.started":"2025-03-21T16:48:59.329549Z","shell.execute_reply":"2025-03-21T17:08:41.608451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\nplt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nprint(\"The Plot of Epochs vs accuracy is:\")\nplt.title(\"Model Accuracy\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nplt.plot(learning_rates, accuracies, marker='o')\nplt.xscale('log')\nplt.xlabel('Learning Rate')\nplt.ylabel('Validation Accuracy')\nplt.title('Validation Accuracy vs. Learning Rate')\nplt.grid(True)\nprint(\"The Plot of learning rate vs accuracy is:\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(history.history[\"\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save(\"waste_segregation_model.h5\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\n\ndef predict_waste(img_path, model):\n    img = image.load_img(img_path, target_size=IMG_SIZE)\n    img_array = image.img_to_array(img) / 255.0  \n    img_array = np.expand_dims(img_array, axis=0)  \n\n    predictions = model.predict(img_array)\n    predicted_class = np.argmax(predictions)  \n    class_names = list(train_generator.class_indices.keys())  \n    return class_names[predicted_class]\n\ntest_img = \"/kaggle/input/waste-segregation-image-dataset/test/sample.jpg\"  # Change this path\npredicted_label = predict_waste(test_img, model)\nprint(\"Predicted Waste Category:\", predicted_label)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}